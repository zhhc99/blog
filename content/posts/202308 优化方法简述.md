---
title: 优化方法简述
slug: optimization-methods-summary
date: 2023-08-15
author: hc
summary: 未完成的最优化笔记, 但可以很好地测试各种数学环境是否正确渲染.
tags:
  - Optimization
---

&emsp; 这里的笔记对优化问题和其数值方法做最基本的介绍, 例如:

- 问题的概念和分类
- 问题的求解方法
- 求解器的大致原理

&emsp; 笔记中没有这些问题的答案:

- 严格的理论分析, 如算法收敛性质的证明
- 先进的求解算法. 请参考 [MOSEK](https://www.mosek.com/), [CVXOPT](https://cvxopt.org/) 等
- 不基于微分的数值方法

**目录**

- [概述](#概述)
  - [优化问题: 概念与分类](#优化问题-概念与分类)
  - [优化方法: 迭代与搜索](#优化方法-迭代与搜索)
- [最优性判定](#最优性判定)
  - [Lagrange 函数](#lagrange-函数)
  - [对偶问题](#对偶问题)
  - [KKT 条件](#kkt-条件)
- [优化算法 I](#优化算法-i)
  - [线搜索的方法](#线搜索的方法)
  - [常用线搜索方向](#常用线搜索方向)
  - [拟 Newton 方法](#拟-newton-方法)
  - [松弛问题](#松弛问题)
- [优化算法 II](#优化算法-ii)
  - [内点方法](#内点方法)
  - [序列二次规划](#序列二次规划)
- [优化算法 III](#优化算法-iii)
  - [交替方向乘子方法](#交替方向乘子方法)
  - [病态情形处理](#病态情形处理)
- [优化算法 IV](#优化算法-iv)
  - [二次规划](#二次规划)
    - [活动集方法](#活动集方法)
  - [线性规划](#线性规划)
  - [二阶锥优化](#二阶锥优化)
- [附: 记号与约定](#附-记号与约定)
  - [向量运算](#向量运算)
  - [向量微分](#向量微分)
  - [其他约定](#其他约定)

## 概述

&emsp; 我们先来明确要探究的问题.

### 优化问题: 概念与分类

&emsp; 一般形式的优化问题是指极值问题

<span id="eq-opt-standard"></span>

$$
\begin{align*}
  & \min_{x} && f(x) \\
  & \mathop{\mathrm{s.t.}} && g(x) \leq 0 \\
  &                        && h(x) = 0,
\end{align*} \tag{1}
$$

其中自变量 $x$ 是 $n$ 维向量; 目标函数 $f$ 是标量值函数; $g$ 和 $h$ 分别是 $m$ 和 $m_e$ 维向量值函数, 表示 $m$ 个不等式约束和 $m_e$ 个等式约束. 若不加特别说明, 我们假设问题中的函数都二阶连续可微.

&emsp; 问题的**可行解**是指满足 $g(x) \leq 0$ 且 $h(x) = 0$ 的点 $x$; 问题的**可行集** (feasible set) 为所有可行解构成的集合. [式 1](#eq-opt-standard) 的解称为问题的**最优解** (optimal solution) , 其对应的目标函数值称为**最优值**.

&emsp; 一些优化问题比较特殊, 如:

- 线性规划 (linear programming, LP). 其形式为

<span id="eq-lp"></span>

$$
\begin{align*}
  & \min_{x} && q^\top x \\
  & \mathop{\mathrm{s.t.}} && A_{in} x - b_{in} \leq 0 \\
  &                        && A_{eq} x - b_{eq} = 0.
\end{align*} \tag{2}
$$

- 二次规划 (quadratic programming, QP). 其形式为

<span id="eq-qp"></span>

$$
\begin{align*}
  & \min_{x} && x^\top H x + q^\top x \\
  & \mathop{\mathrm{s.t.}} && A_{in} x - b_{in} \leq 0 \\
  &                        && A_{eq} x - b_{eq} = 0.
\end{align*} \tag{3}
$$

- 凸优化 (convex optimization). 其形式与 [式 1](#eq-opt-standard) 相同, 但 $f$ 和 $g$ 的每个分量都是凸定义域上的凸函数, $h$ 是仿射变换. 这类问题具有较好的性质, 容易找到最优解. LP 总是凸优化; QP 在 $H$ 为 PSD 时总是凸优化.

&emsp; 接下来我们将着重于讨论一些数值方法, 它们用于寻找优化问题 [式 1](#eq-opt-standard) 的局部最优解, 记作 $x^\star$, 对应的局部最优值记作 $f^\star$. 一个容易理解的事实是, 数值方法没有能力判断该解是否也为全局最优解, 所以我们**不区分局部最优解和最优解**的概念, 尤其是在讨论算法实现时.

### 优化方法: 迭代与搜索

&emsp; 多数优化算法用**迭代**的方法求解 [式 1](#eq-opt-standard), 即: 从一个起始点 $x = x_0$ 出发, 根据某种规则, 一步步地更新 $x$. 当 $x$ 在数值上满足一定的最优性条件时, 算法就认为 $x$ 是最优解.

&emsp; 对 $x$ 的迭代大致有两种基本方法. 基于**线搜索**的迭代过程如下:

- 在 $x$ 处计算搜索步 $d_x$ 作为**搜索方向**;
- 沿着 $d_x$, 搜索新的迭代点 $x^+ = x + \alpha d_x$, 其中 $0 < \alpha \leq 1$. 该过程称为**线搜索** (line search);
- 更新 $x := x^+$, 重复这些过程.

算法着重考虑的问题是, 如何确定适当的搜索方向, 以及如何进行线搜索. 在进行线搜索时, 算法往往要构造一个**评价函数** (merit function) $\psi$, 用于评估迭代点的好坏. 一般地, 评价函数的值要在迭代后严格下降, 即 $\psi(x^+) < \psi(x)$. 如果存在 $0 < \alpha \leq 1$ 使得 $\psi(x^+) = \psi(x + \alpha d_x) < \psi(x)$, 就称 $d_x$ 为一个**可行方向**.

&emsp; 另一种迭代基于**信赖域**, 其迭代过程如下:

- 在 $x$ 处计算优化问题 [式 1](#eq-opt-standard) 的一个近似问题 (往往是二次规划);
- 预估一个该近似问题与原问题拟合较好的区域. 该区域称为**信赖域** (trust region);
- 计算近似问题在信赖域中的解或近似解.
- 用评价函数评估该解. 如果该解足够好, 就用该解更新 $x$; 反之, 缩小信赖域, 重新求解近似问题, 直到解足够好.

信赖域的选取策略与具体迭代算法构造的近似问题有关, 确定一个策略离不开严格的理论分析. 该方法的迭代步不局限于某个搜索方向, 往往有着更稳定的收敛性.

## 最优性判定

&emsp; 在介绍优化算法之前, 一个需要解决的问题是, 如何才能判断给定的 $x$ 是否为最优解. 对于最一般的情况, 您需要计算 $f$ 在 $x$ 邻域内的所有值, 并与 $f(x)$ 比较. 这样做当然不现实. 对于可微函数, 它在某个点处取得极值的必要条件是梯度为 $0$, 所以数值梯度可以用于最优性判定. 从数值分析的角度出发, 您可能会想到, $f$ 的高阶微分能用于构造最优性的充分条件, 例如 $f$ 在一个点处梯度消失, 且 Hessian 矩阵非负. 但是, 计算高阶数值微分的代价大, 并且对于

$$
  f(x) = e^{-x^2}
$$

这样的目标函数, 无论在 $x = 0$ 处检验几阶数值微分, 都不能确定该点是最优解.

&emsp; 在实际的计算中, 人们一般用所谓的**一阶最优性条件**, 或称为 **KKT 条件**, 来检查 $x$ 是否为最优解, 这样做有着多方面的考量. 下面将逐步介绍理解 KKT 条件所需的知识.

### Lagrange 函数

&emsp; 为了将约束融合进目标函数, 我们介绍所谓的 **Lagrange 函数**. 一般优化问题 [(式 1)](#eq-opt-standard) 的 Lagrange 函数定义为

$$
  \mathcal{L}(x,u,v) = f(x) + g(x)^\top u + h(x)^\top v,
$$

其中 $u$ 和 $v$ 称为**乘子**或**对偶变量**, 分别对应不等式约束 $g$ 和等式约束 $h$. 当 $u \geq 0$ 时, 对每个可行解 $x$ 都有

$$
  \mathcal{L}(x,u,v) \leq f(x),
$$

这是因为此时 $g(x) \leq 0$ 以及 $h(x) = 0$. 进一步地, 用 $\mathcal{F}$ 表示原问题的可行集, 只要 $u$ 非负, 就有

$$
  \min_x \mathcal{L}(x,u,v) \leq \min_{x \in \mathcal{F}} \mathcal{L}(x,u,v) \leq \min_{x \in \mathcal{F}} f(x).
$$

&emsp; **Lagrange 对偶函数** $l(u,v)$ 就定义为不等式最左侧的项:

$$
  l(u,v) = \min_x \mathcal{L}(x,u,v).
$$

请不要与 Lagrange 函数混淆. 按定义, $l(u,v) > -\infty$ 当且仅当存在 $x$ 极小化 $\mathcal{L}(x,u,v)$. 并且, 当 $u \geq 0$ 时, $l(u,v)$ 也是 $f$ 在 $\mathcal{F}$ 上的下界.

### 对偶问题

&emsp; 在约束条件 $u \geq 0$ 下, 极大化 Lagrange 对偶函数, 使其尽可能接近 $f^\star$:

<span id="eq-opt-dual"></span>

$$
\begin{align*}
  & \max_{u,v} && l(u,v) \\
  & \mathop{\mathrm{s.t.}} && u \geq 0,
\end{align*} \tag{4}
$$

或者写成

$$
\begin{align*}
  & \max_{u,v} \min_{x}    && f(x) + g(x)^\top u + h(x)^\top v \\
  & \mathop{\mathrm{s.t.}} && u \geq 0,
\end{align*}
$$

该问题称为**对偶问题** (dual problem), 对应的优化问题 [(式 1)](#eq-opt-standard) 称为**原始问题** (primal problem). 可以证明, 对偶问题总是凸优化.

&emsp; 差值 $f^\star - l^\star$ 称为**对偶差** (duality gap), 该数值用于衡量原始问题和对偶问题的相关性. 从上一节的讨论中您能看出, 对偶差始终非负, 这被称为**弱对偶性** (weak duality). 对于某个优化问题, 当其对偶差为 $0$ 时, 称**强对偶性** (strong duality) 成立. 多数凸优化问题都具有强对偶性.

&emsp; LP 的对偶问题一般有更特殊的表示. 考虑 LP [(式 2)](#eq-lp), 它的 Lagrange 对偶函数为

$$
\begin{align*}
  l(u,v)
  &= \min_x ~ q^\top x + (A_{in} x - b_{in})^\top u + (A_{eq} x - b_{eq})^\top v \\
  &= \min_x ~ (q + A_{in}^\top u + A_{eq}^\top v)^\top x - b_{in}^\top u - b_{eq}^\top v.
\end{align*}
$$

当关于 $x$ 的线性项的系数 $q + A_{in}^\top u + A_{eq}^\top v$ 不为 $0$ 时, 有 $l(u,v) = -\infty$, 所以 $l(u,v)$ 取得最大值时, $A_{in}^\top u + A_{eq}^\top v + q = 0$ 必须成立. 经过一点代数上的整理, 我们得到 LP 的对偶问题:

$$
\begin{align*}
  & \min_{u,v} && b_{in}^\top u + b_{eq}^\top v \\
  & \mathop{\mathrm{s.t.}} && u \geq 0 \\
  &                        && A_{in}^\top u + A_{eq}^\top v + q = 0.
\end{align*}
$$

### KKT 条件

&emsp; 现在可以介绍所谓的一阶最优性条件, 也就是 Karush–Kuhn–Tucker 条件, 或简称为 KKT 条件:

<span id="eq-kkt"></span>

$$
\begin{align*}
  \nabla f(x) + J_g(x)^\top u + J_h(x)^\top v &= 0 \\
  g(x) \leq 0, h(x) &= 0 \\
  u & \geq 0 && \\
  u \odot g(x) & = 0
\end{align*} \tag{5}
$$

&emsp; 从上到下的四行分别称为: **稳定性**, **原始可行性**, **对偶可行性** 和 **互补松弛性**. 在多数情况下, **基于微分的优化算法实际上以求解 KKT 条件为目标**, 即寻找可行的迭代点和乘子, 使得 Lagrange 函数到达稳定点, 并对不等式约束满足互补松弛性.

&emsp; 当优化问题 [式 1](#eq-opt-standard) 不含有不等式约束时, KKT 条件等价于 $\nabla \mathcal{L}(x,v) = 0$. 更一般地, 在一定的假设下, KKT 条件等价于 $(x, u, v)$ 是原始问题 [(式 1)](#eq-opt-standard) 和对偶问题 [(式 4)](#eq-opt-dual) 的解:

- 当 $(x^\star, u^\star, v^\star)$ 是原问题和对偶问题的解时, KKT 条件中的原始可行性和对偶可行性自然要得到满足. 假设强对偶性成立, 那么有

$$
\begin{align*}
  f(x^\star)
  & = l(u^\star, v^\star) \\
  & = \min_x f(x) + g(x)^\top u^\star + h(x)^\top v^\star \\
  & \leq f(x^\star) + g(x^\star)^\top u^\star + h(x^\star)^\top v^\star \\
  & \leq f(x^\star),
\end{align*}
$$

其中最后一个不等号是因为 $g(x^\star)^\top u \leq 0$ 以及 $h(x^\star) = 0$. 您可以发现, 不等式最右侧和最左侧的项相同, 这说明式中的不等号都是等号. 其中倒数第二个不等号对应的关系式变成

$$
  \min_x \mathcal{L}(x,u^\star,v^\star) = \mathcal{L}(x^\star,u^\star,v^\star),
$$

这说明 $x^\star$ 极小化 $\mathcal{L}(x, u^\star, v^\star)$, 所以 KKT 条件中的稳定性成立; 另一方面, 因为 $g(x^\star)$ 和 $u^\star$ 所有对应元素的符号都相反, 所以互补松弛性必须成立, 才能让最后一个不等式成为等式.

- 当 $(\tilde{x},\tilde{u},\tilde{v})$ 满足 KKT 条件时, 假设 $\mathcal{L}(x,\tilde{u},\tilde{v})$ 是关于 $x$ 的凸函数, 那么稳定性条件等价于在说 $\tilde{x}$ 极小化 $\mathcal{L}(x,\tilde{u},\tilde{v})$, 即

$$
  l(\tilde{u},\tilde{v}) = \mathcal{L}(\tilde{x},\tilde{u},\tilde{v}) = f(\tilde{x}) + g(\tilde{x})^\top \tilde{u} + h(\tilde{x})^\top \tilde{v}.
$$

由 KKT 条件中的互补松弛性和可行性, 最右侧只剩 $f(\tilde{x})$ 一项不为 $0$. 结合弱对偶性, 我们得到不等式

$$
  f^\star \leq f(\tilde{x}) = l(\tilde{u},\tilde{v}) \leq l^\star \leq f^\star,
$$

并且式中的不等号同样都是等号. 这说明强对偶性成立, 并且 $(\tilde{x},\tilde{u},\tilde{v})$ 正是原问题和对偶问题的最优解.

&emsp; 对于凸优化问题, KKT 条件可以用[次微分](https://en.wikipedia.org/wiki/Subderivative)来更准确地刻画.

## 优化算法 I

&emsp; 这节介绍一些优化算法中常用的方法和技巧.

### 线搜索的方法

&emsp; 线搜索方法大致分为两类: 精确线搜索和非精确线搜索. 前者要求计算 $\phi(\alpha) = \psi(x + \alpha d_x)$ 在 $0 < \alpha \leq 1$ 范围内的局部极小值, 而后者只要求 $\phi(\alpha)$ 的值充分小于 $\phi(0)$.

&emsp; 我们介绍几种线搜索方法. **黄金分割搜索** (golden-section search) 是一种较为简单的精确线搜索方法, 它的实现非常简单, 也无需额外计算梯度. 优化算法中往往不使用精确线搜索, 因为它比非精确线搜索慢, 也未必能给迭代步带来额外的进展. 对于非精确线搜索, 一种简单的方法是遍历, 或称为**回溯线搜索** (backtracking line search), 即先设置 $\alpha$ 尽可能大, 然后逐渐减小 $\alpha$, 直到 $\phi(\alpha)$ 的值相对 $\phi(0)$ 充分下降. 此外, 您可以用多项式插值等技术, 使得线搜索的结果满足 Wolfe 条件:

$$
\begin{cases}
  \psi(x + \alpha d_x)                  & \leq \psi(x) + c_1 \alpha \nabla \psi(x)^\top d_x \\
  \nabla \psi (x + \alpha d_x)^\top d_x & \geq c_2 \nabla \psi(x)^\top d_x,
\end{cases}
$$

其中 $0 < c_1 < c_2 < 1$, 比如取 $c_1 = 0.0001$ 和 $c_2 = 0.9$. 该条件对于之后介绍的拟 Newton 方法有帮助.

### 常用线搜索方向

&emsp; 为了让问题的讨论简单化, 我们考虑无约束优化问题. 这类问题的 Lagrange 函数就是 $f$ 自身, 考虑对偶问题也没有意义, 这使得算法所要做的事情非常直接: 让 $f(x)$ 随着迭代而充分下降, 直到 $f$ 稳定, 即 KKT 条件 $\nabla f(x) = 0$ 得到满足.

&emsp; 将 $f$ 在 $x$ 处做微分展开, 有

$$
  f(x + s) = f(x) + \nabla f(x)^\top s + O(s^2),
$$

其中 $s = \alpha d_x$. 当 $x$ 不满足 KKT 条件时, $\nabla f(x) \neq 0$. 取评价函数 $\psi(x) = f(x)$. 您可以看出, **负梯度方向** $-\nabla f(x)$ 就是一个使得 $\psi$ 下降的可行方向, 因为此时一阶项非 $0$, 而高阶项在邻域充分小时相对于低阶项被忽略. 利用负梯度方向进行搜索的优化方法称为**梯度下降** (gradient descent).

&emsp; 还可以考虑更高阶的微分展开, 例如二阶微分展开

$$
  f(x + s) = f(x) + \nabla f(x)^\top s + \frac{1}{2} s^\top \nabla^2 f(x) s + O(s^3),
$$

其中 $s = \alpha d_x$. 记 $H = \nabla^2 f(x)$. 如果我们找到 $H$ 的**负曲率方向**, 即满足

$$
  d^\top H d < 0
$$

的方向 $d$, 就可以构造一个使得 $\psi$ 下降的可行方向. 这是因为, 您总是可以选取 $d$ 的符号, 使得

$$
  \nabla f(x)^\top d \leq 0
$$

成立, 然后该负曲率方向就可以作为下降方向 $d_x$, 用于线搜索. 如果 $H$ 不是 PSD, 那么 $H$ 有负的特征值, 其负曲率方向总是存在的.

&emsp; 您也可以直接用所谓的 [Newton-Raphson 迭代方法](https://en.wikipedia.org/wiki/Newton%27s_method)来计算 $\nabla f(x)$ 的根, 也就是 $f(x)$ 的稳定点. 该方法的每一步迭代为 $x^+ = x + s$, 其中

$$
  \nabla^2 f(x) s = -\nabla f(x).
$$

当 $H = \nabla^2 f(x)$ 严格正定时, 该步等同于在计算二阶近似问题

$$
\begin{align*}
  & \min_s && f(x) + \nabla f(x)^\top s + \frac{1}{2} s^\top \nabla^2 f(x) s
\end{align*}
$$

的精确解. 对于原来的问题, $H$ 未必严格正定, 该近似也未必准确, 但由

$$
  \nabla^2 f(x) d_x = -\nabla f(x)
$$

确定的方向 $d_x$ 仍能帮助求解. 该方向称为 **Newton 方向**. 对于正定的无约束二次规划问题, 上述二阶近似是精确的, 因此步长 $\alpha = 1$ 的 Newton 步将直接获得最优解; 对于一般的无约束优化问题, Newton 方向未必是下降方向, 但当 $x$ 充分接近最优解 $x^\star$, 且问题严格局部凸时, 上述二阶近似将较为准确, 此时 Newton 方向能大大加快收敛速度.

&emsp; 对于带约束的优化问题, 上面介绍的几个搜索方向在经过一定修改后仍然具有意义. 不同的算法可能对这些方向做不同的修改, 在这里我们仅对 Newton 方向做一点说明. 当优化问题 [(式 1)](#eq-opt-standard) 仅含有等式约束时, KKT 条件 [(式 5)](#eq-kkt) 也仅含有等式:

$$
\begin{align*}
  \nabla f(x) + J_h(x)^\top v &= 0 \\
  h(x) &= 0, \\
\end{align*}
$$

该方程组同样可以用 Newton-Raphson 迭代方法来求解, 迭代方程为

$$
\begin{bmatrix*}
  W(x,v) & J_h(x)^\top \\
  J_h(x) & 0
\end{bmatrix*}
\begin{bmatrix*}
  d_x \\
  d_v
\end{bmatrix*} = -
\begin{bmatrix*}
  \nabla f(x) + J_h(x)^\top v \\
  h(x)
\end{bmatrix*},
$$

其中 $W$ 为 Lagrange 函数的梯度 $\nabla^2_{xx} \mathcal{L}(x,v)$. 这里的 $d_x$ (和 $d_v$, 如果考虑对偶变量) 仍称为 Newton 方向. 许多算法尝试在该方向上进行线搜索, 希望能改进评价函数, 该评价函数既要衡量 $f$ 的下降程度, 又要衡量等式约束的满足程度, 如

$$
\psi(x,v) = f(x) + \nu \lVert h(x) \rVert,
$$

其中 $\nu$ 是非负参数.

### 拟 Newton 方法

&emsp; 我们已经知道, 对于仅含有等式约束的优化问题, 在计算 Newton 方向时, 需要先计算 Lagrange 函数的 Hessian 矩阵 $W(x,v)$. 事实上, 对于一般的优化问题 [(式 1)](#eq-opt-standard), 许多算法仍要计算 Lagrange 函数的 Hessian 矩阵 $W(x,u,v)$. 这一步将消耗大量时间, 并且, 计算得到的 $W$ 可能不是正定的, 这将阻碍一些算法的进行. 人们希望用更低的代价计算出 $W$ 的替代矩阵 $B$, 使得 Newton 步的结果基本不变, 并且保证该替代矩阵的正定性. 这类方法称为**拟 Newton 方法**, 应用最广的是 SR1 (对称秩 1) 校正方法和 **BFGS 方法**. 在这里我们仅介绍 BFGS 方法.

&emsp; 假设前一步迭代为 $x \rightarrow x^+$, $x$ 处的替代矩阵 $B$ 已经得到, 并且 $B$ 是正定的. 为 $B$ 增加一个秩为 $2$ 的校正量:

$$
  B^+ = B + \frac{q q^\top}{q^\top s} - \frac{B s s^\top B}{s^\top B s},
$$

其中

$$
\begin{align*}
  q & = \nabla_x \mathcal{L}(x^+,u^+,v^+) - \nabla_x \mathcal{L}(x,u^+,v^+); \\
  s & = x^+ - x,
\end{align*}
$$

得到的 $B^+$ 就是 $x^+$ 处的替代矩阵, 这就是所谓的 Broyden–Fletcher–Goldfarb–Shanno 方法, 或称为 BFGS 方法. 可以证明, 当 $q^\top s > 0$ 时, $B^+$ 仍是正定的; 当 $q^\top s \leq 0$ 时, 人们也有许多保持 $B^+$ 仍是正定的方法: 有些算法直接令 $B^+ = B$, 另一些算法尝试对 $q^\top s$ 进行修正. Powell 给出了一种能够从两个正定矩阵的凸组合上选择 $B^+$ 的算法, 他令 $\theta = \displaystyle \frac{0.8 s^\top B s}{s^\top B s - q^\top s}$, 然后将 $q$ 修改为

$$
  q := \theta q + (1-\theta) Bs,
$$

再用上面的方法计算 $B^+$ 就可保持 $B^+$ 正定.

&emsp; BFGS 方法速度快, 并且能保持矩阵的正定性, 是拟 Newton 方法的代表. 在迭代的第一步, 您可以选取 $B = I$ 作为初始矩阵, 从而完全避免 Hessian 矩阵的计算. 几乎所有需要计算 Hessian 矩阵的算法都会采用拟 Newton 方法.

### 松弛问题

&emsp; 处理优化问题 [式 1](#eq-opt-standard) 中不等式约束的基本方法是引入**松弛变量** (slack variables). 令 $s = -g(x)$, 问题变成

<span id="eq-opt-slack"></span>

$$
\begin{align*}
  & \min_{x,s} && f(x) \\
  & \mathop{\mathrm{s.t.}} && s \geq 0 \\
  &                        && g(x) + s = 0 \\
  &                        && h(x) = 0,
\end{align*} \tag{6}
$$

称为松弛问题, 或直接看作原问题的另一种等价表示形式. 在这里, 松弛变量 $s$ 将复杂的不等式约束转化成简单的框约束 (box constraint).

&emsp; 求解松弛问题 [式 6](#eq-opt-slack) 而不是原问题 [式 1](#eq-opt-standard) 有许多好处. 比如, 框约束的初始可行点更容易寻找. 您将在后续的算法中体会到松弛方法的更多好处.

## 优化算法 II

&emsp; 这节我们主要介绍处理优化问题 [式 1](#eq-opt-standard) 中不等式约束的方法: 内点方法和序列二次规划方法.

### 内点方法

&emsp; **内点方法** (interior-point methods) 是处理优化问题不等式约束的一种方法. 在迭代求解的过程中, 优化问题的一阶最优性条件 [式 5](#eq-kkt) 可以这样刻画:

- 迭代点满足 KKT 条件的等式约束;
- 迭代点是可行集 (和对偶可行集) 的内点.

内点方法的核心思想是, 保持迭代点是内点, 并让迭代点逐步满足 KKT 条件 [式 5](#eq-kkt) 的等式约束.

&emsp;

### 序列二次规划

## 优化算法 III

### 交替方向乘子方法

### 病态情形处理

## 优化算法 IV

### 二次规划

#### 活动集方法

### 线性规划

### 二阶锥优化

## 附: 记号与约定

### 向量运算

&emsp; 所有的向量都是列向量; $e$ 表示所有元素都为 $1$ 的列向量.

&emsp; 逐元素运算: "$\odot$" 和 "$\oslash$" 分别表示向量 (或矩阵) 的逐元素乘法和除法.

### 向量微分

&emsp; **Jacobi 矩阵** (一阶微分): 当 $f \in \mathbb{R}^{n \times 1} \rightarrow \mathbb{R}^{m \times 1}$ 时, $J_f \in \mathbb{R}^{n \times 1} \rightarrow \mathbb{R}^{m \times n}$, 其中 $J_f$ 的 $(i,j)$ 元为 $D_j f_i$, 也就是

$$
  J_f = \begin{bmatrix}
  \nabla f_1 & \cdots & \nabla f_m
  \end{bmatrix}^\top.
$$

如:

$$
\begin{gather*}
  f(x) = Ax - b, & J_f(x) = A \\
  f(x) = x^\top Ax, & J_f(x) = x^\top (A+A^\top)
\end{gather*}
$$

&emsp; **Hessian 矩阵** (二阶微分): 当 $f \in \mathbb{R}^{n \times 1} \rightarrow \mathbb{R}$ 时, $\nabla^2 f = H_f \in \mathbb{R}^{n \times 1} \rightarrow \mathbb{R}^{n \times n}$, 其中 $H_f$ 的 $(i,j)$ 元为 $D_i D_j f$, 也就是 $H_f = (J_{J_f^\top})^\top$.

&emsp; 函数的**微分展开**: 当 $f \in \mathbb{R}^{n \times 1} \rightarrow \mathbb{R}$ 二阶连续可微时, $H_f$ 是对称矩阵, 有二次近似式

$$
  f(x + s) = f(x) + J_f(x)s + \frac{1}{2} s^\top H_f(x) s + O(s^3).
$$

### 其他约定

&emsp; 所有问题都在实数域上讨论.
